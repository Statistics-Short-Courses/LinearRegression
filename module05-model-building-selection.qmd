---
title: "Model Building and Selection"
format:
  live-html:
    toc: true
---

## Exploratory analysis for model formulation

- Start with plots (pairs, scatterplots, boxplots) to understand ranges,
  outliers, and plausible functional forms.
- Use subject-matter knowledge to posit candidate predictors and
  interactions.

## Systematic vs random variation

- Distinguish signal (systematic trend with predictors) from noise
  (unexplained scatter).
- Residual SD estimates random variation; large unexplained scatter may
  indicate missing predictors or wrong functional form.

## Choosing first- vs second-order functional forms

- Start with additive, first-order (linear) terms; add interactions or
  low-order polynomials when plots or theory suggest them.
- Prefer centered predictors to stabilise estimates when adding
  higher-order terms.

## Model adequacy and interpretability

- Adequate models fit the data (diagnostics pass) *and* support the
  scientific question.
- Avoid models that obscure interpretation with unnecessary complexity
  or unidentifiable effects.

## Parsimony as a guiding principle

- Favor the simplest model that explains the data and meets assumptions.
- Remove immaterial terms when they do not improve fit or align with
  theory; compare nested models via F-tests or information criteria.

## Multicollinearity: detection and implications

- Symptoms: unstable coefficients, inflated standard errors, signs
  flipping with small data changes ([multicollinearity](#gloss-multicollinearity)).
- Quick checks: pairwise correlations, variance inflation factors (VIF),
  or condition numbers.

```{r}
cor(mtcars[, c("wt", "hp", "disp", "drat")])
kappa(model.matrix(~ wt + hp + disp, data = mtcars))
```

## Akaike Information Criterion (AIC)

- Balances fit and complexity: $\text{AIC} = -2\ell + 2k$; lower is
  better ([AIC](#gloss-aic)).
- Compare non-nested models with `AIC(model1, model2, ...)`.

## Forward, backward, and stepwise selection

- Forward: start simple, add terms that reduce AIC or improve fit.
- Backward: start saturated, remove weak terms.
- Stepwise: alternate add/drop using `step()` (AIC by default).

```{r}
full_mod <- lm(mpg ~ ., data = mtcars)
step(full_mod, direction = "both", trace = 0)
```

## Limitations and cautions for stepwise methods

- Data-driven searches can overfit and inflate Type I error.
- Selected models depend on starting set and may ignore theory; always
  validate with diagnostics and, if possible, new data.

## Balancing prediction and explanation

- For explanation, prioritise interpretability and scientific
  plausibility; for prediction, prioritise out-of-sample performance.
- Consider cross-validation or a hold-out set when sample size permits;
  report uncertainty from the final, diagnostically-sound model.
