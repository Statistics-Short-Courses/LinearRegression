---
format: 
  live-html:
    toc: true

execute:
  echo: true
  warning: false
  message: false

embed-resources: true

filters:
  - custom-numbered-blocks

custom-numbered-blocks:
  classes:
    Assumption:
      colors: [FFCDD2, F44336]
      boxstyle: foldbox.simple
      collapse: false
    Example:
      colors: [BBDEFB, 2196F3]
      boxstyle: foldbox.simple
      collapse: false
    Exercise:
      colors: [C8E6C9, 4CAF50]
      boxstyle: foldbox.simple
      collapse: false
    Technical-point:
      colors: [FFF9C4, FFEB3B]
      boxstyle: foldbox.simple
      collapse: true
webr:
  render-df: gt-interactive
---

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}} {{< include ./_extensions/r-wasm/live/_gradethis.qmd >}}

```{webr}
#| include: false
library(tidyverse)
set_theme(theme_bw())
```

# Inference about population parameters

So far, we have been given sample of data that we assumed came from a linear model, and attemped to *estimate* that model based on the data. However, since we only have a *sample* (and not an not the entire *population*), there is *uncertainty* in our estimates. How confident are we that our estimates, $a$, $b$ are good representations of the 'true' population parameters $\alpha$, $\beta$? Assessing this uncertainty is the subject of *statistical inference,* and will us to draw conclusions about the usefulness of our model and the reliability of the predictions it makes[^1].

-  [ ]

[^1]: For a more general introduction to statistical inference, you may refer to the 'Inferential Statistics with R' short course. If any of the assumed content here (e.g. Normal distribution, t-tests) feels unfamiliar, please revise that course before continuing.


## Inference about the slope, $\beta$
As noted in @sec-chap1, our main interest is modelling the relationship between two variables. With this in mind, the main parameter of interest in our simple linear model is the slope parameter, $\beta$, since it represents the change in the response variable given a (1-unit) change in the predictor, X. Therefore we will focus this section on inference for $\beta$, however, note that a similar process can be applied to the intercept parameter $\alpha$. 


-   **Objective:** Derive sampling distributions for $a$ and $b$ under the model assumptions.
-   **Key results:** Emphasise unbiasedness, variance formulas, and the joint normality of the estimators.
-   **Confidence intervals:** Outline the structure $a \pm t_{n-2,\alpha/2} \cdot \operatorname{SE}(a)$ (and similarly for $b$).
-   **Hypothesis tests:** Summarise how to test linear contrasts of the coefficients using t-statistics.

### Inference about $\sigma$

-   **Distributional result:** With the assumptions above, the scaled residual sum of squares follows a $\chi^2_{n-2}$ distribution.

-   **Confidence interval:** Show how this leads to bounds for $\sigma$ using chi-squared quantiles.

-   **Hypothesis test:** Note the form of tests comparing error variance claims.

-   **Software link:** Point to the `sigma` output and degrees of freedom in R for practical calculation. 

## Interpreting \`summary()\` output

-   **Purpose:** `summary()` wraps the model fit, assumptions, and inference into a single report.
-   **Coefficients table:** Highlight estimates, standard errors, t-values, and p-values for $\alpha$ and $\beta$.
-   **Residual standard error:** Connect this to $\hat \sigma$ and the degrees of freedom shown in the output.
-   **Model fit metrics:** Explain multiple $R^2$ and adjusted $R^2$ as measures of explained variation.
-   **Overall test:** Describe how the F-statistic in simple regression aligns with the $\beta$ t-test.
-   **Workflow tip:** Encourage students to read the table line by line, linking each quantity back to the modelling steps above.

Interpreting each component in context helps translate the statistical output into practical insight about the data.

## Using the model for prediction

-   **Prerequisite:** Only use the model for prediction after diagnostics suggest the assumptions hold.
-   **Point prediction:** Use `predict()` to obtain fitted values for new $x$.
-   **Interval estimates:** Emphasise the difference between confidence intervals for the mean response and prediction intervals for individual outcomes.
-   **Communicating uncertainty:** Always report the uncertainty associated with predictions.
-   **Scope of application:** Warn about extrapolating beyond the observed range of $x$ and discuss potential pitfalls.

test.

## possible exercises

-   calculate residuals manually from beta coefficients
